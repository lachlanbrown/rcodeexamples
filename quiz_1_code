## Question 1:

## The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here: 
  
##   https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv 

## and load the data into R. The code book, describing the variable names is here: 

##   https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf 

## How many properties are worth $1,000,000 or more?

dir.create("idaho_housing")
Housing_file <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv?accessType=DOWNLOAD"
## designate download destination to a variable
download.file(Housing_file, destfile = "idaho_housing/idaho_housing.csv")
## download the csv file, rename and store in directory
HousingData <- read.table("idaho_housing/idaho_housing.csv", sep = ",", header = TRUE)
## load data from directory/csv file into R data frame - 188 variables
Mil_Plus <- subset(HousingData, VAL %in% '24')
## create data frame that subsets HousingData where column Val equals 24, which is numeric code for Million plus homes
## the # of obs. equals the number of mil+ homes

## Question #3:
## Download the Excel spreadsheet on Natural Gas Aquisition Program here: 
  
##   https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx 
library(xlsx)
Gas_Data <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx?accessType=DOWNLOAD"
download.file(Gas_Data, destfile="data/gas.xlsx", mode = "wb")
## Read rows 18-23 and columns 7-15 into R and assign the result to a variable called:
##   dat 
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("data/gas.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
## What is the value of:
  sum(dat$Zip*dat$Ext,na.rm=T)
  
## Question #4
##  Read the XML data on Baltimore restaurants from here: 
  ##    https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml 
library(XML)
XMLUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(XMLUrl, destfile="data/Balt_Rest.xml", quiet=T)
rest_doc <- xmlTreeParse("data/Balt_Rest.xml", useInternal=T)
## since XML library doesn't support https, had to use download file and then xmlTreeParse on local doc
##  How many restaurants have zipcode 21231?
zip <- xpathSApply(rest_doc, "//zipcode", xmlValue)
length(zip[zip=='21231'])

## Question #5
## The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here: 
  
##  https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv 

Housing_file2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv?accessType=DOWNLOAD"
## designate download destination to a variable
download.file(Housing_file2, destfile = "idaho_housing/idaho_housing2.csv")
## download the csv file, rename and store in directory

## using the fread() command load the data into an R object

#  DT 

DT <- fread("idaho_housing/idaho_housing2.csv")

## Which of the following is the fastest way to calculate the average value of the variable

## pwgtp15 

## broken down by sex using the data.table package?

## tapply(DT$pwgtp15,DT$SEX,mean) - calculates correctly
## DT[,mean(pwgtp15),by=SEX] - calculates correctly - winner!
## rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] - returns error
## mean(DT$pwgtp15,by=DT$SEX) - only returns single value, not broken out
## mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) - calculates correctly
## sapply(split(DT$pwgtp15,DT$SEX),mean) - calculates correctly

## method 1, write a for loop or use replicate to test the time of each 1000 times and report on results:
system.time(for(i in 1:1000) {tapply(DT$pwgtp15,DT$SEX,mean)}) ##using first expression above
## OR
system.time(replicate(1000, tapply(DT$pwgtp15,DT$SEX,mean)))
## method 2, use microbenchmark package
library(microbenchmark)
microbenchmark(tapply(DT$pwgtp15,DT$SEX,mean)) ##using first expression above, did not work for #5, which had two expressions separated by ;

